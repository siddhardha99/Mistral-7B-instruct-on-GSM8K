{
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 7045423,
          "sourceType": "datasetVersion",
          "datasetId": 4054119
        },
        {
          "sourceId": 11261,
          "sourceType": "modelInstanceVersion",
          "modelInstanceId": 8332
        },
        {
          "sourceId": 5112,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": true,
          "modelInstanceId": 3900
        }
      ],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 4190.684325,
      "end_time": "2023-12-17T22:21:21.061832",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-12-17T21:11:30.377507",
      "version": "2.4.0"
    },
    "colab": {
      "name": "Mistral 7B-instruct on GSM8K",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "thedevastator_grade_school_math_8k_q_a_path = kagglehub.dataset_download('thedevastator/grade-school-math-8k-q-a')\n",
        "mistral_ai_mistral_pytorch_7b_instruct_v0_1_hf_1_path = kagglehub.model_download('mistral-ai/mistral/PyTorch/7b-instruct-v0.1-hf/1')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "CnPS75Xfrds4"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U torch --index-url https://download.pytorch.org/whl/cu117"
      ],
      "metadata": {
        "papermill": {
          "duration": 12.837112,
          "end_time": "2023-12-17T21:11:46.656292",
          "exception": false,
          "start_time": "2023-12-17T21:11:33.81918",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-26T18:43:14.230789Z",
          "iopub.execute_input": "2024-04-26T18:43:14.231032Z",
          "iopub.status.idle": "2024-04-26T18:43:18.645242Z",
          "shell.execute_reply.started": "2024-04-26T18:43:14.231006Z",
          "shell.execute_reply": "2024-04-26T18:43:18.644112Z"
        },
        "trusted": true,
        "id": "aPatrbH0rds5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U transformers==\"4.38.2\"\n",
        "!pip install -q accelerate\n",
        "!pip install -q -i https://pypi.org/simple/ bitsandbytes\n",
        "!pip install -q -U datasets"
      ],
      "metadata": {
        "papermill": {
          "duration": 25.835818,
          "end_time": "2023-12-17T21:12:12.500193",
          "exception": false,
          "start_time": "2023-12-17T21:11:46.664375",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-26T18:43:18.647134Z",
          "iopub.execute_input": "2024-04-26T18:43:18.647412Z",
          "iopub.status.idle": "2024-04-26T18:43:56.140331Z",
          "shell.execute_reply.started": "2024-04-26T18:43:18.647383Z",
          "shell.execute_reply": "2024-04-26T18:43:56.139104Z"
        },
        "trusted": true,
        "id": "BKxYsZa-rds5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U trl==0.8.5\n",
        "!pip install -q -U git+https://github.com/huggingface/peft"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T18:43:56.141835Z",
          "iopub.execute_input": "2024-04-26T18:43:56.142159Z",
          "iopub.status.idle": "2024-04-26T18:44:11.852635Z",
          "shell.execute_reply.started": "2024-04-26T18:43:56.142125Z",
          "shell.execute_reply": "2024-04-26T18:44:11.851407Z"
        },
        "trusted": true,
        "id": "XbYBJhvqrds5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ],
      "metadata": {
        "papermill": {
          "duration": 0.015679,
          "end_time": "2023-12-17T21:12:12.539544",
          "exception": false,
          "start_time": "2023-12-17T21:12:12.523865",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-26T18:44:11.854678Z",
          "iopub.execute_input": "2024-04-26T18:44:11.855074Z",
          "iopub.status.idle": "2024-04-26T18:44:11.859658Z",
          "shell.execute_reply.started": "2024-04-26T18:44:11.855036Z",
          "shell.execute_reply": "2024-04-26T18:44:11.858933Z"
        },
        "trusted": true,
        "id": "-smXowJRrds5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch_xla\n",
        "# import torch_xla.core.xla_model as xm"
      ],
      "metadata": {
        "id": "KC519_uKrds5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.01423,
          "end_time": "2023-12-17T21:12:12.576944",
          "exception": false,
          "start_time": "2023-12-17T21:12:12.562714",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "dfypUsQ9rds5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import transformers\n",
        "from transformers import (AutoModelForCausalLM,\n",
        "                          AutoTokenizer,\n",
        "                          BitsAndBytesConfig,\n",
        "                          TrainingArguments,\n",
        "                          pipeline,\n",
        "                          logging)\n",
        "from datasets import Dataset\n",
        "from peft import LoraConfig, PeftConfig\n",
        "import bitsandbytes as bnb\n",
        "from trl import SFTTrainer\n",
        "\n",
        "from sklearn.metrics import (accuracy_score,\n",
        "                             classification_report,\n",
        "                             confusion_matrix)\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "papermill": {
          "duration": 19.450408,
          "end_time": "2023-12-17T21:12:32.05101",
          "exception": false,
          "start_time": "2023-12-17T21:12:12.600602",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "FMun9RkPrds6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1\"\n",
        "\n",
        "compute_dtype = getattr(torch, \"float16\")\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=False,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=compute_dtype,\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map=\"auto\",\n",
        "    quantization_config=bnb_config,\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "GbqFp4T-rds6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1\"\n",
        "\n",
        "max_seq_length = 2048\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, max_seq_length=max_seq_length)\n",
        "EOS_TOKEN = tokenizer.eos_token"
      ],
      "metadata": {
        "trusted": true,
        "id": "gu-Dw_dGrds6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"/kaggle/input/grade-school-math-8k-q-a/main_train.csv\"\n",
        "\n",
        "df = pd.read_csv(filename)\n",
        "df"
      ],
      "metadata": {
        "trusted": true,
        "id": "KAwDyN_Rrds6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainfilename = \"/kaggle/input/grade-school-math-8k-q-a/main_train.csv\"\n",
        "testfilename = \"/kaggle/input/grade-school-math-8k-q-a/main_test.csv\"\n",
        "\n",
        "traindf = pd.read_csv(trainfilename)\n",
        "# traindf = traindf.drop(['title'],axis=1)\n",
        "\n",
        "traindf, evaldf = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "testdf = pd.read_csv(testfilename)\n",
        "# testdf = testdf.drop(['title'],axis=1)\n",
        "\n",
        "#selecting the firsst 100 rows only\n",
        "# testdf = testdf[:50]\n",
        "# evaldf = evaldf[:3]\n",
        "# traindf = traindf[:3]"
      ],
      "metadata": {
        "trusted": true,
        "id": "cKOQekJ4rds6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prompt_gsm8k(data_point):\n",
        "    return f\"\"\"{data_point['question']} [SEP] {data_point['answer']}\n",
        "            \"\"\".strip() + EOS_TOKEN\n",
        "\n",
        "def generate_prompt_test_gsm8k(data_point):\n",
        "    return f\"\"\"\n",
        "            Instruction: Give a very short numeric solution with in 30 words or less.\n",
        "\n",
        "            Question: Joy can read 8 pages of a book in 20 minutes. How many hours will it take her to read 120 pages?\n",
        "            Solution: In one hour, there are 3 sets of 20 minutes. So, Joy can read 8 x 3 = <<8*3=24>>24 pages in an hour. It will take her 120/24 = <<120/24=5>>5 hours to read 120 pages. #### 5\n",
        "\n",
        "            Question: {data_point['question']}.\n",
        "            Solution:\n",
        "            \"\"\".strip()\n",
        "\n",
        "import re\n",
        "ANS_RE = re.compile(r\"#### (\\-?[0-9\\.\\,]+)\")\n",
        "INVALID_ANS = \"[invalid]\"\n",
        "def extract_the_answer(data_point):\n",
        "#     print(data_point)\n",
        "    match = ANS_RE.search(data_point['answer'])\n",
        "    if match:\n",
        "        match_str = match.group(1).strip()\n",
        "        match_str = match_str.replace(\",\", \"\")\n",
        "        return match_str\n",
        "    else:\n",
        "        return INVALID_ANS\n",
        "X_train = pd.DataFrame(traindf.apply(generate_prompt_gsm8k, axis=1), columns=[\"question\"])\n",
        "X_eval = pd.DataFrame(evaldf.apply(generate_prompt_test_gsm8k, axis=1), columns=[\"question\"])\n",
        "\n",
        "y_true = pd.DataFrame(testdf.apply(extract_the_answer, axis=1), columns=[\"answer\"])\n",
        "X_test = pd.DataFrame(testdf.apply(generate_prompt_test_gsm8k, axis=1), columns=[\"question\"])\n",
        "\n",
        "train_data = Dataset.from_pandas(X_train)\n",
        "eval_data = Dataset.from_pandas(X_eval)"
      ],
      "metadata": {
        "trusted": true,
        "id": "zF-RXUoMrds6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0]"
      ],
      "metadata": {
        "trusted": true,
        "id": "mV8ZLsUVrds6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = pd.DataFrame(traindf.apply(generate_prompt_gsm8k, axis=1), columns=[\"question\",])"
      ],
      "metadata": {
        "trusted": true,
        "id": "H2p7mBrXrds6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(y_true, y_pred):\n",
        "    labels = [True, False, None]\n",
        "    mapping = {True: 1, False: 0, None: 2}\n",
        "    def map_func(x):\n",
        "        return x\n",
        "\n",
        "    y_true = np.vectorize(map_func)(y_true)\n",
        "    y_pred = np.vectorize(map_func)(y_pred)\n",
        "\n",
        "    accuracy = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
        "    print(f'Accuracy: {accuracy:.3f}')"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.021281,
          "end_time": "2023-12-17T21:12:32.668587",
          "exception": false,
          "start_time": "2023-12-17T21:12:32.647306",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "_buVUtOZrds6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SUBSTITUTIONS = [\n",
        "    ('an ', ''), ('a ', ''), ('.$', '$'), ('\\\\$', ''), (r'\\ ', ''), ('\\%', '%'),\n",
        "    (' ', ''), ('mbox', 'text'), (',\\\\text{and}', ','),\n",
        "    ('\\\\text{and}', ','), ('\\\\text{m}', '\\\\text{}')\n",
        "]\n",
        "REMOVED_EXPRESSIONS = [\n",
        "    'square', 'ways', 'integers', 'dollars', 'mph', 'inches', 'ft',\n",
        "    'hours', 'km', 'units', '\\\\ldots', 'sue', 'points', 'feet',\n",
        "    'minutes', 'digits', 'cents', 'degrees', 'cm', 'gm', 'pounds',\n",
        "    'meters', 'meals', 'edges', 'students', 'childrentickets', 'multiples',\n",
        "    '\\\\text{s}', '\\\\text{.}', '\\\\text{\\ns}', '\\\\text{}^2',\n",
        "    '\\\\text{}^3', '\\\\text{\\n}', '\\\\text{}', r'\\mathrm{th}',\n",
        "    r'^\\circ', r'^{\\circ}', r'\\;', r',\\!', '{,}', '\"', '\\\\dots'\n",
        "]\n",
        "\n",
        "def normalize_final_answer(final_answer: str) -> str:\n",
        "    \"\"\"Normalize a final answer to a quantitative reasoning question.\"\"\"\n",
        "    final_answer = final_answer.split('=')[-1]\n",
        "\n",
        "    for before, after in SUBSTITUTIONS:\n",
        "        final_answer = final_answer.replace(before, after)\n",
        "    for expr in REMOVED_EXPRESSIONS:\n",
        "        final_answer = final_answer.replace(expr, '')\n",
        "\n",
        "    final_answer = re.sub(r'(.*?)(\\$)(.*?)(\\$)(.*)', '$\\\\3$', final_answer)\n",
        "    final_answer = re.sub(r'(\\\\text\\{)(.*?)(\\})', '\\\\2', final_answer)\n",
        "    final_answer = re.sub(r'(\\\\textbf\\{)(.*?)(\\})', '\\\\2', final_answer)\n",
        "    final_answer = re.sub(r'(\\\\overline\\{)(.*?)(\\})', '\\\\2', final_answer)\n",
        "    final_answer = re.sub(r'(\\\\boxed\\{)(.*)(\\})', '\\\\2', final_answer)\n",
        "\n",
        "    final_answer = re.sub(\n",
        "        r'(frac)([^{])(.)', 'frac{\\\\2}{\\\\3}', final_answer)\n",
        "    final_answer = re.sub(\n",
        "        r'(sqrt)([^{])', 'sqrt{\\\\2}', final_answer)\n",
        "    final_answer = final_answer.replace('$', '')\n",
        "\n",
        "    final_answer = final_answer.replace(',', '')\n",
        "\n",
        "    return final_answer"
      ],
      "metadata": {
        "trusted": true,
        "id": "8b8WXUT9rds7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true_predict = y_true[\"answer\"].tolist()\n",
        "def predict(X_test, model, tokenizer, y_true):\n",
        "    y_pred = []\n",
        "    for i in tqdm(range(len(X_test))):\n",
        "        prompt = X_test.iloc[i][\"question\"]\n",
        "        input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "        outputs = model.generate(**input_ids, max_new_tokens=100, temperature=0.0)\n",
        "        result = tokenizer.decode(outputs[0])\n",
        "        answer = result.split(\"Solution:\")[-1]\n",
        "        answer = normalize_final_answer(answer)\n",
        "        pattern = re.compile(fr\"[^0-9]*{y_true_predict[i]}[^0-9]+\")\n",
        "        match = re.search(pattern, answer)\n",
        "        print(pattern)\n",
        "        print(answer)\n",
        "        if match:\n",
        "            y_pred.append(y_true_predict[i])\n",
        "            print(\"matched!\")\n",
        "        else:\n",
        "            y_pred.append(int(y_true_predict[i])+1)\n",
        "    return y_pred"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.020352,
          "end_time": "2023-12-17T21:14:01.321014",
          "exception": false,
          "start_time": "2023-12-17T21:14:01.300662",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "ymXQ4KnErds7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = predict(X_test, model, tokenizer, y_true)"
      ],
      "metadata": {
        "papermill": {
          "duration": 366.910332,
          "end_time": "2023-12-17T21:20:08.260576",
          "exception": false,
          "start_time": "2023-12-17T21:14:01.350244",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "9E0n1MiErds7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"fine-tuned on 6 row \")\n",
        "evaluate(y_true, y_pred)"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.115727,
          "end_time": "2023-12-17T21:20:08.612213",
          "exception": false,
          "start_time": "2023-12-17T21:20:08.496486",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "7opZ2NY5rds7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "trusted": true,
        "id": "u8-VhrPPrds7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "peft_config = LoraConfig(\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0,\n",
        "    r=64,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                    \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        ")\n",
        "\n",
        "training_arguments = TrainingArguments(\n",
        "    output_dir=\"logs\",\n",
        "    num_train_epochs=5,\n",
        "    gradient_checkpointing=True,\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=8,\n",
        "    optim=\"paged_adamw_32bit\",\n",
        "    save_steps=0,\n",
        "    logging_steps=25,\n",
        "    learning_rate=2e-4,\n",
        "    weight_decay=0.001,\n",
        "    fp16=True,\n",
        "    bf16=False,\n",
        "    max_grad_norm=0.3,\n",
        "    max_steps=-1,\n",
        "    warmup_ratio=0.03,\n",
        "    group_by_length=False,\n",
        "    evaluation_strategy='steps',\n",
        "    eval_steps = 112,\n",
        "    eval_accumulation_steps=1,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    report_to=\"tensorboard\",\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=eval_data,\n",
        "    peft_config=peft_config,\n",
        "    dataset_text_field=\"question\",\n",
        "    tokenizer=tokenizer,\n",
        "    max_seq_length=max_seq_length,\n",
        "    args=training_arguments,\n",
        "    packing=False,\n",
        ")"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.907911,
          "end_time": "2023-12-17T21:20:09.767766",
          "exception": false,
          "start_time": "2023-12-17T21:20:08.859855",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "0Tetc9qkrds7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "trainer.train()\n",
        "\n",
        "# Save trained model\n",
        "trainer.model.save_pretrained(\"trained-model-12\")"
      ],
      "metadata": {
        "papermill": {
          "duration": 3279.391068,
          "end_time": "2023-12-17T22:14:49.397236",
          "exception": false,
          "start_time": "2023-12-17T21:20:10.006168",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "tBtamtoirds7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Afterwards, loading the TensorBoard extension and start TensorBoard, pointing to the logs/runs directory, which is assumed to contain the training logs and checkpoints for your model, will allow you to understand how the models fits during the training."
      ],
      "metadata": {
        "papermill": {
          "duration": 0.080308,
          "end_time": "2023-12-17T22:14:49.560957",
          "exception": false,
          "start_time": "2023-12-17T22:14:49.480649",
          "status": "completed"
        },
        "tags": [],
        "id": "VNBXMwvhrds7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs/runs"
      ],
      "metadata": {
        "papermill": {
          "duration": 7.617207,
          "end_time": "2023-12-17T22:14:57.258758",
          "exception": false,
          "start_time": "2023-12-17T22:14:49.641551",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "wVc4PPjfrds8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code will first predict the sentiment labels for the test set using the predict() function. Then, it will evaluate the model's performance on the test set using the evaluate() function. The result now should be impressive with an overall accuracy of over 0.8 and high accuracy, precision and recall for the single sentiment labels. The prediction of the neutral label can still be improved, yet it is impressive how much could be done with little data and some fine-tuning."
      ],
      "metadata": {
        "papermill": {
          "duration": 0.079228,
          "end_time": "2023-12-17T22:14:57.418749",
          "exception": false,
          "start_time": "2023-12-17T22:14:57.339521",
          "status": "completed"
        },
        "tags": [],
        "id": "5TTb6VuTrds8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = predict(X_test, model, tokenizer)\n",
        "evaluate(y_true, y_pred)"
      ],
      "metadata": {
        "papermill": {
          "duration": 379.935342,
          "end_time": "2023-12-17T22:21:17.436577",
          "exception": false,
          "start_time": "2023-12-17T22:14:57.501235",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "MAsw7lzurds8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation = pd.DataFrame({'question': X_test[\"question\"],\n",
        "                           'y_true':y_true,\n",
        "                           'y_pred': y_pred},\n",
        "                         )\n",
        "evaluation.to_csv(\"test_predictions.csv\", index=False)"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.182657,
          "end_time": "2023-12-17T22:21:18.077143",
          "exception": false,
          "start_time": "2023-12-17T22:21:17.894486",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "gJ5aoIaErds8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}